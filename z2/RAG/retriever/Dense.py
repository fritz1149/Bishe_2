import json
import os
import numpy as np
import torch
import faiss
from typing import List, Dict, Optional, Tuple
from tqdm import tqdm
from z2.RAG.utils import save_corpus


class DenseRetriever:
    """
    åŸºäº FAISS çš„ç¨ å¯†å‘é‡æ£€ç´¢å™¨ã€‚
    
    ä½¿ç”¨ TrafficEmbedder æ¨¡å‹å¯¹æ–‡æ¡£è¿›è¡Œç¼–ç ï¼Œæ„å»º FAISS ç´¢å¼•è¿›è¡Œé«˜æ•ˆæ£€ç´¢ã€‚
    
    Example:
        >>> retriever = DenseRetriever(args)
        >>> retriever.save_corpus([{'id': 'doc1', 'contents': 'æ–‡æ¡£å†…å®¹'}], 'corpus.jsonl')
        >>> retriever.build_index('corpus.jsonl', 'index_dir')
        >>> results = retriever.search('æŸ¥è¯¢æ–‡æœ¬', 'index_dir', k=5)
    """
    
    def __init__(self, args, device: str = None):
        """
        åˆå§‹åŒ–æ£€ç´¢å™¨ã€‚
        
        Args:
            args: æ¨¡å‹å‚æ•°ï¼Œéœ€åŒ…å« TrafficEmbedder æ‰€éœ€çš„é…ç½®
            device: è®¾å¤‡ ('cuda' æˆ– 'cpu')ï¼ŒNone åˆ™è‡ªåŠ¨é€‰æ‹©
        """
        self.args = args
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.processor = None
    
    def _load_model(self):
        """å»¶è¿ŸåŠ è½½æ¨¡å‹"""
        if self.model is None:
            from z2.model import TrafficEmbedder
            from transformers import AutoProcessor
            
            self.model = TrafficEmbedder(self.args)
            self.model.to(self.device)
            self.model.eval()
            
            self.processor = AutoProcessor.from_pretrained(self.args.llm)
            
            print(f"âœ… æ¨¡å‹å·²åŠ è½½: TrafficEmbedder (è®¾å¤‡: {self.device})")
    
    @torch.no_grad()
    def encode(self, texts: List[str], batch_size: int = 8, normalize: bool = True) -> np.ndarray:
        """
        å¯¹æ–‡æœ¬åˆ—è¡¨è¿›è¡Œç¼–ç ï¼Œè¿”å›å‘é‡ã€‚
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            normalize: æ˜¯å¦å¯¹å‘é‡è¿›è¡Œ L2 å½’ä¸€åŒ–
        
        Returns:
            np.ndarray: å½¢çŠ¶ä¸º (len(texts), hidden_dim) çš„å‘é‡æ•°ç»„
        """
        self._load_model()
        
        all_embeddings = []
        
        for i in tqdm(range(0, len(texts), batch_size), desc="Encoding"):
            batch_texts = texts[i:i + batch_size]
            
            inputs = self.processor(
                text=batch_texts,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors='pt'
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            embeddings = self.model(**inputs, normalize=normalize)
            
            all_embeddings.append(embeddings.cpu().numpy())
        
        return np.vstack(all_embeddings)
    
    def build_index(
        self,
        corpus_file: str,
        index_dir: str,
        batch_size: int = 8,
        index_type: str = 'flat',
        verbose: bool = True
    ) -> None:
        """
        ä»è¯­æ–™æ–‡ä»¶æ„å»º FAISS ç´¢å¼•ã€‚
        
        Args:
            corpus_file: è¯­æ–™æ–‡ä»¶è·¯å¾„ (.jsonl)
            index_dir: ç´¢å¼•ä¿å­˜ç›®å½•
            batch_size: ç¼–ç æ—¶çš„æ‰¹å¤„ç†å¤§å°
            index_type: ç´¢å¼•ç±»å‹ ('flat' æˆ– 'ivf')
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        if not os.path.exists(corpus_file):
            raise FileNotFoundError(f"è¯­æ–™æ–‡ä»¶ä¸å­˜åœ¨: {corpus_file}")
        
        os.makedirs(index_dir, exist_ok=True)
        
        # è¯»å–è¯­æ–™
        doc_ids = []
        doc_contents = []
        
        with open(corpus_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                doc = json.loads(line)
                doc_ids.append(doc['id'])
                doc_contents.append(doc['contents'])
        
        if verbose:
            print(f"ğŸ“„ å·²åŠ è½½ {len(doc_ids)} ä¸ªæ–‡æ¡£")
        
        # ç¼–ç æ–‡æ¡£
        if verbose:
            print("ğŸ”„ æ­£åœ¨ç¼–ç æ–‡æ¡£...")
        embeddings = self.encode(doc_contents, batch_size=batch_size)
        
        # ä½¿ç”¨å…±äº«çš„ç´¢å¼•æ„å»ºå‡½æ•°
        from z2.RAG.vector_utils import build_faiss_index
        
        build_faiss_index(
            embeddings=embeddings,
            doc_ids=doc_ids,
            doc_contents=doc_contents,
            index_dir=index_dir,
            index_type=index_type,
            verbose=verbose
        )
    
    def search(
        self,
        query: str,
        index_dir: str,
        k: int = 10,
        return_contents: bool = True,
        verbose: bool = False
    ) -> List[Tuple[str, float, Optional[str]]]:
        """
        ä½¿ç”¨ç¨ å¯†å‘é‡è¿›è¡Œ top-k æ£€ç´¢ã€‚
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            index_dir: ç´¢å¼•ç›®å½•è·¯å¾„
            k: è¿”å› top-k ç»“æœæ•°é‡
            return_contents: æ˜¯å¦è¿”å›æ–‡æ¡£å†…å®¹
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
        Returns:
            List[Tuple[str, float, Optional[str]]]: (doc_id, score, contents) åˆ—è¡¨
        """
        # ç¼–ç æŸ¥è¯¢
        query_embedding = self.encode([query], batch_size=1)
        
        # ä½¿ç”¨å…±äº«çš„æ£€ç´¢å‡½æ•°
        from z2.RAG.vector_utils import search_faiss_index
        
        results = search_faiss_index(
            query_embedding=query_embedding,
            index_dir=index_dir,
            k=k,
            return_contents=return_contents
        )
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯
        if verbose:
            for i, (doc_id, score, content) in enumerate(results, 1):
                print(f"\næ’å {i}: {doc_id} (åˆ†æ•°: {score:.4f})")
                if content:
                    print(f"å†…å®¹: {content[:200]}..." if len(content) > 200 else f"å†…å®¹: {content}")
            print(f"\nâœ… æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
        
        return results


# ä¾¿æ·å‡½æ•°ï¼Œå…¼å®¹ BM25 é£æ ¼çš„æ¥å£
_default_retriever = None

def _get_retriever(args=None) -> DenseRetriever:
    """è·å–æˆ–åˆ›å»ºé»˜è®¤æ£€ç´¢å™¨"""
    global _default_retriever
    if _default_retriever is None:
        if args is None:
            raise ValueError("é¦–æ¬¡è°ƒç”¨éœ€è¦ä¼ å…¥ args å‚æ•°")
        _default_retriever = DenseRetriever(args)
    return _default_retriever


def build_index(
    args,
    corpus_file: str,
    index_dir: str = 'dense_index',
    batch_size: int = 8,
    verbose: bool = True
) -> None:
    """ä»è¯­æ–™æ–‡ä»¶æ„å»º FAISS ç´¢å¼•"""
    retriever = _get_retriever(args)
    retriever.build_index(corpus_file, index_dir, batch_size, verbose=verbose)


def search(
    args,
    query: str,
    index_dir: str = 'dense_index',
    k: int = 10,
    return_contents: bool = True,
    verbose: bool = False
) -> List[Tuple[str, float, Optional[str]]]:
    """ä½¿ç”¨ç¨ å¯†å‘é‡è¿›è¡Œ top-k æ£€ç´¢"""
    retriever = _get_retriever(args)
    return retriever.search(query, index_dir, k, return_contents, verbose)